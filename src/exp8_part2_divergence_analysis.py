
"""
Experiment 8 Part 2: Divergence Analysis of Submodule Outputs

This script compares the submodule outputs generated by exp8_part1_submodule_output_generation.py
from two different runs (e.g., on different GPUs or with different settings).

Purpose:
--------
Analyzes the outputs to pinpoint where and how they diverge.
1.  Finds the first token at which the generated text diverges.
2.  At the point of divergence and the token immediately preceding it, this script compares:
    -   Embeddings
    -   Input layer norms
    -   Post-attention layer norms
    -   Embeddings before and after the final layer norm.

Input Requirements:
-------------------
Expects two directories, each containing the results from an exp8_part1 run.
Each directory should have a structure like:
-   question_01/
    -   words.json
    -   embeddings.npy
    -   input_layernorms.npy
    -   post_attention_layernorms.npy
    -   final_norm_embeddings.npy
-   question_02/
    ...

Methodology:
------------
1.  Load the generated word sequences from both result folders.
2.  Identify the first index where the words differ (the divergence index).
3.  If a divergence is found:
    a.  For the divergence index:
        i.  Load the embeddings, input layer norms, post-attention layer norms, and final norm embeddings.
        ii. Compare these tensors between the two runs using cosine similarity and L2 distance.
    b.  For the index immediately preceding the divergence:
        i.  Perform the same comparisons as for the divergence index.
4.  Output a JSON file containing the detailed comparison results.

Use Case:
---------
This script is used to understand the precise point of model output divergence
and to analyze the differences in various internal model states (submodule outputs)
that may have led to the divergence.
"""

import json
import numpy as np
import argparse
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from scipy.spatial.distance import cosine, euclidean

def find_divergence_index(generated1: List[str], generated2: List[str]) -> Optional[int]:
    """Find the first index where generated words diverge"""
    num_tokens = min(len(generated1), len(generated2))
    
    for i in range(num_tokens):
        if generated1[i] != generated2[i]:
            return i
    
    return None  # No divergence found

def load_comparison_data(result_dir: Path, question_id: int, index: int) -> Dict[str, np.ndarray]:
    """Load all necessary data for a given question and index."""
    question_dir = result_dir / f"question_{question_id:02d}"
    data = {}
    
    try:
        with open(question_dir / "words.json", 'r') as f:
            data['words'] = json.load(f)['generated_words']

        # Load input embeddings
        embeddings = np.load(question_dir / "input_embeddings.npy")
        data['embedding'] = embeddings[index]

        # Load layer 0 input layernorm
        input_ln = np.load(question_dir / "layer0_input_layernorm_outputs.npy")
        data['input_layernorm'] = input_ln[index]

        # Load layer 0 post-attention layernorm
        post_attn_ln = np.load(question_dir / "layer0_post_attention_layernorm_outputs.npy")
        data['post_attention_layernorm'] = post_attn_ln[index]

        # Load last layer before norm (if you want to use it)
        last_layer_before_norm = np.load(question_dir / "last_layer_before_norm_outputs.npy")
        data['last_layer_before_norm'] = last_layer_before_norm[index]

        # Load final norm outputs (corrected filename)
        final_norm_outputs = np.load(question_dir / "final_norm_outputs.npy")
        data['final_norm'] = final_norm_outputs[index]

    except FileNotFoundError as e:
        print(f"Error loading data for question {question_id} at index {index} from {result_dir}: {e}")
        return {}

    return data

def compare_tensors(tensor1: np.ndarray, tensor2: np.ndarray) -> Dict[str, float]:
    """Compare two tensors using cosine similarity and L2 distance."""
    return {
        'cosine_similarity': 1 - cosine(tensor1, tensor2),
        'l2_distance': euclidean(tensor1, tensor2)
    }

def main():
    parser = argparse.ArgumentParser(description="Analyze divergence between two experiment 8 runs.")
    parser.add_argument("folder1", type=str, help="Path to the first results folder.")
    parser.add_argument("folder2", type=str, help="Path to the second results folder.")
    parser.add_argument("--output_file", type=str, default="divergence_analysis.json", help="File to save the analysis results.")
    parser.add_argument("--num_questions", type=int, default=1, help="Number of questions to compare.")
    args = parser.parse_args()

    folder1 = Path(args.folder1)
    folder2 = Path(args.folder2)
    
    all_results = {}

    for i in range(1, args.num_questions + 1):
        question_id = i
        print(f"Comparing question {question_id}...")

        try:
            with open(folder1 / f"question_{question_id:02d}" / "words.json", 'r') as f:
                words1 = json.load(f)['generated_words']
            with open(folder2 / f"question_{question_id:02d}" / "words.json", 'r') as f:
                words2 = json.load(f)['generated_words']
        except FileNotFoundError:
            print(f"Could not find words.json for question {question_id}. Skipping.")
            continue

        divergence_idx = find_divergence_index(words1, words2)

        if divergence_idx is None:
            print("No divergence found for this question.")
            all_results[f"question_{question_id:02d}"] = {"status": "no_divergence"}
            continue

        print(f"Divergence found at index: {divergence_idx}")
        previous_idx = divergence_idx - 1
        
        results = {
            'divergence_index': divergence_idx,
            'divergent_words': {
                'folder1': words1[divergence_idx],
                'folder2': words2[divergence_idx]
            },
            'comparison_at_divergence': {},
            'comparison_at_previous': {}
        }

        # Analysis at the point of divergence
        data1_div = load_comparison_data(folder1, question_id, divergence_idx)
        data2_div = load_comparison_data(folder2, question_id, divergence_idx)

        if data1_div and data2_div:
            results['comparison_at_divergence'] = {
                'embedding': compare_tensors(data1_div['embedding'], data2_div['embedding']),
                'input_layernorm': compare_tensors(data1_div['input_layernorm'], data2_div['input_layernorm']),
                'post_attention_layernorm': compare_tensors(data1_div['post_attention_layernorm'], data2_div['post_attention_layernorm']),
                'last_layer_before_norm': compare_tensors(data1_div['last_layer_before_norm'], data2_div['last_layer_before_norm']),
                'final_norm': compare_tensors(data1_div['final_norm'], data2_div['final_norm']),
            }

        # Analysis at the point just before divergence
        if previous_idx >= 0:
            data1_prev = load_comparison_data(folder1, question_id, previous_idx)
            data2_prev = load_comparison_data(folder2, question_id, previous_idx)

            if data1_prev and data2_prev:
                results['comparison_at_previous'] = {
                    'embedding': compare_tensors(data1_prev['embedding'], data2_prev['embedding']),
                    'input_layernorm': compare_tensors(data1_prev['input_layernorm'], data2_prev['input_layernorm']),
                    'post_attention_layernorm': compare_tensors(data1_prev['post_attention_layernorm'], data2_prev['post_attention_layernorm']),
                    'last_layer_before_norm': compare_tensors(data1_prev['last_layer_before_norm'], data2_prev['last_layer_before_norm']),
                    'final_norm': compare_tensors(data1_prev['final_norm'], data2_prev['final_norm']),
                }

        all_results[f"question_{question_id:02d}"] = results

    with open(args.output_file, 'w') as f:
        json.dump(all_results, f, indent=4)

    print(f"Analysis complete. Results saved to {args.output_file}")

if __name__ == "__main__":
    main()

'''
python src/exp8_part2_divergence_analysis.py results/A5000_exp8_part1_2025-10-30_12-09-20/ results/A6000_exp8_part1_2025-10-30_12-13-27 --num_questions 10
'''