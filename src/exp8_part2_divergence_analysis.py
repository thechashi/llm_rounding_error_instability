"""
Experiment 8 Part 2: Comprehensive Divergence Analysis of All Submodule Outputs

This script compares ALL submodule outputs generated by the comprehensive exp8_part1
from two different runs (e.g., on different GPUs or with different settings).

Purpose:
--------
Analyzes the outputs to pinpoint where and how they diverge across ALL layers and submodules.
1.  Finds the first token at which the generated text diverges.
2.  At the point of divergence and the token immediately preceding it, compares:
    -   Input embeddings
    -   For each layer: input_layernorm, self_attn, attn_o_proj, post_attention_layernorm,
        mlp_gate_proj, mlp_up_proj, mlp_act_fn, mlp_down_proj, mlp
    -   Last layer before norm
    -   Final norm

Input Requirements:
-------------------
Expects two directories, each containing the results from a comprehensive exp8_part1 run.
Each directory should have a structure like:
-   question_01/
    -   words.json
    -   input_embeddings.npy
    -   layer0_input_layernorm.npy
    -   layer0_self_attn.npy
    -   layer0_attn_o_proj.npy
    -   ... (all submodules for all layers)
    -   last_layer_before_norm.npy
    -   final_norm.npy
-   question_02/
    ...

Methodology:
------------
1.  Load the generated word sequences from both result folders.
2.  Identify the first index where the words differ (the divergence index).
3.  If a divergence is found:
    a.  For the divergence index:
        i.  Load ALL submodule outputs from both runs.
        ii. Compare these tensors using cosine similarity and L2 distance.
    b.  For the index immediately preceding the divergence:
        i.  Perform the same comprehensive comparisons.
4.  Output a JSON file containing the detailed comparison results.

Use Case:
---------
This script provides a comprehensive analysis to understand the precise point of model 
output divergence across ALL internal states (submodule outputs) that may have led 
to the divergence.
"""

import json
import numpy as np
import argparse
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from scipy.spatial.distance import cosine, euclidean

def find_divergence_index(generated1: List[str], generated2: List[str]) -> Optional[int]:
    """Find the first index where generated words diverge"""
    num_tokens = min(len(generated1), len(generated2))
    
    for i in range(num_tokens):
        if generated1[i] != generated2[i]:
            return i
    
    return None  # No divergence found

def detect_num_layers(question_dir: Path) -> int:
    """
    Detect the number of layers by counting layer-specific .npy files.
    """
    layer_files = list(question_dir.glob("layer*_input_layernorm.npy"))
    num_layers = len(layer_files)
    return num_layers

def load_comprehensive_data(result_dir: Path, question_id: int, index: int, num_layers: int) -> Dict[str, np.ndarray]:
    """Load ALL submodule data for a given question and index."""
    question_dir = result_dir / f"question_{question_id:02d}"
    data = {}
    
    try:
        # Load generated words metadata
        with open(question_dir / "words.json", 'r') as f:
            data['words'] = json.load(f)['generated_words']

        # Load input embeddings
        input_embeddings_path = question_dir / "input_embeddings.npy"
        if input_embeddings_path.exists():
            embeddings = np.load(input_embeddings_path)
            data['input_embeddings'] = embeddings[index]

        # Load all layer submodules
        for layer_idx in range(num_layers):
            submodules = [
                'input_layernorm',
                'self_attn',
                'attn_o_proj',
                'post_attention_layernorm',
                'mlp_gate_proj',
                'mlp_up_proj',
                'mlp_act_fn',
                'mlp_down_proj',
                'mlp',
            ]
            
            for submodule in submodules:
                filename = f"layer{layer_idx}_{submodule}.npy"
                filepath = question_dir / filename
                
                if filepath.exists():
                    try:
                        submodule_data = np.load(filepath)
                        data[f'layer{layer_idx}_{submodule}'] = submodule_data[index]
                    except Exception as e:
                        print(f"  Warning: Could not load {filename}: {e}")

        # Load last layer before norm
        last_layer_path = question_dir / "last_layer_before_norm.npy"
        if last_layer_path.exists():
            last_layer = np.load(last_layer_path)
            data['last_layer_before_norm'] = last_layer[index]

        # Load final norm
        final_norm_path = question_dir / "final_norm.npy"
        if final_norm_path.exists():
            final_norm = np.load(final_norm_path)
            data['final_norm'] = final_norm[index]

    except FileNotFoundError as e:
        print(f"Error loading data for question {question_id} at index {index} from {result_dir}: {e}")
        return {}
    except IndexError as e:
        print(f"Index {index} out of range for question {question_id} in {result_dir}: {e}")
        return {}

    return data

def compare_tensors(tensor1: np.ndarray, tensor2: np.ndarray) -> Dict[str, float]:
    """Compare two tensors using cosine similarity and L2 distance."""
    try:
        cos_sim = 1 - cosine(tensor1.flatten(), tensor2.flatten())
        l2_dist = euclidean(tensor1.flatten(), tensor2.flatten())
        
        # Additional metrics
        max_abs_diff = np.max(np.abs(tensor1 - tensor2))
        mean_abs_diff = np.mean(np.abs(tensor1 - tensor2))
        
        return {
            'cosine_similarity': float(cos_sim),
            'l2_distance': float(l2_dist),
            'max_absolute_difference': float(max_abs_diff),
            'mean_absolute_difference': float(mean_abs_diff)
        }
    except Exception as e:
        print(f"Error comparing tensors: {e}")
        return {
            'cosine_similarity': None,
            'l2_distance': None,
            'max_absolute_difference': None,
            'mean_absolute_difference': None,
            'error': str(e)
        }

def get_ordered_keys(data: Dict) -> List[str]:
    """
    Get keys in a logical order: input_embeddings, then layers, then final layers.
    """
    ordered_keys = []
    
    if 'input_embeddings' in data:
        ordered_keys.append('input_embeddings')
    
    # Extract layer numbers
    layer_keys = [k for k in data.keys() if k.startswith('layer') and k != 'last_layer_before_norm']
    
    # Sort by layer number and submodule
    def sort_key(k):
        parts = k.split('_', 1)
        layer_num = int(parts[0].replace('layer', ''))
        submodule = parts[1] if len(parts) > 1 else ''
        
        # Define submodule order
        submodule_order = {
            'input_layernorm': 0,
            'self_attn': 1,
            'attn_o_proj': 2,
            'post_attention_layernorm': 3,
            'mlp_gate_proj': 4,
            'mlp_up_proj': 5,
            'mlp_act_fn': 6,
            'mlp_down_proj': 7,
            'mlp': 8,
        }
        
        return (layer_num, submodule_order.get(submodule, 999))
    
    layer_keys_sorted = sorted(layer_keys, key=sort_key)
    ordered_keys.extend(layer_keys_sorted)
    
    if 'last_layer_before_norm' in data:
        ordered_keys.append('last_layer_before_norm')
    
    if 'final_norm' in data:
        ordered_keys.append('final_norm')
    
    return ordered_keys

def analyze_divergence_comprehensive(
    folder1: Path,
    folder2: Path,
    question_id: int,
    divergence_idx: int,
    num_layers: int
) -> Dict:
    """
    Perform comprehensive comparison at divergence point and previous point.
    """
    results = {
        'divergence_index': divergence_idx,
        'divergent_words': {},
        'comparison_at_divergence': {},
        'comparison_at_previous': {},
        'summary_statistics': {}
    }
    
    # Load words to show what diverged
    try:
        with open(folder1 / f"question_{question_id:02d}" / "words.json", 'r') as f:
            words1 = json.load(f)['generated_words']
        with open(folder2 / f"question_{question_id:02d}" / "words.json", 'r') as f:
            words2 = json.load(f)['generated_words']
        
        results['divergent_words'] = {
            'folder1': words1[divergence_idx],
            'folder2': words2[divergence_idx]
        }
    except Exception as e:
        print(f"Could not load words: {e}")
    
    # Analysis at the point of divergence
    print(f"  Loading data at divergence index {divergence_idx}...")
    data1_div = load_comprehensive_data(folder1, question_id, divergence_idx, num_layers)
    data2_div = load_comprehensive_data(folder2, question_id, divergence_idx, num_layers)
    
    if data1_div and data2_div:
        ordered_keys = get_ordered_keys(data1_div)
        
        for key in ordered_keys:
            if key in data1_div and key in data2_div and key != 'words':
                results['comparison_at_divergence'][key] = compare_tensors(
                    data1_div[key], 
                    data2_div[key]
                )
    
    # Analysis at the point just before divergence
    previous_idx = divergence_idx - 1
    if previous_idx >= 0:
        print(f"  Loading data at previous index {previous_idx}...")
        data1_prev = load_comprehensive_data(folder1, question_id, previous_idx, num_layers)
        data2_prev = load_comprehensive_data(folder2, question_id, previous_idx, num_layers)
        
        if data1_prev and data2_prev:
            ordered_keys = get_ordered_keys(data1_prev)
            
            for key in ordered_keys:
                if key in data1_prev and key in data2_prev and key != 'words':
                    results['comparison_at_previous'][key] = compare_tensors(
                        data1_prev[key], 
                        data2_prev[key]
                    )
    
    # Compute summary statistics
    if results['comparison_at_divergence']:
        cos_sims = [v['cosine_similarity'] for v in results['comparison_at_divergence'].values() 
                    if v.get('cosine_similarity') is not None]
        l2_dists = [v['l2_distance'] for v in results['comparison_at_divergence'].values() 
                   if v.get('l2_distance') is not None]
        
        results['summary_statistics']['at_divergence'] = {
            'mean_cosine_similarity': float(np.mean(cos_sims)) if cos_sims else None,
            'min_cosine_similarity': float(np.min(cos_sims)) if cos_sims else None,
            'max_cosine_similarity': float(np.max(cos_sims)) if cos_sims else None,
            'mean_l2_distance': float(np.mean(l2_dists)) if l2_dists else None,
            'max_l2_distance': float(np.max(l2_dists)) if l2_dists else None,
        }
    
    if results['comparison_at_previous']:
        cos_sims = [v['cosine_similarity'] for v in results['comparison_at_previous'].values() 
                    if v.get('cosine_similarity') is not None]
        l2_dists = [v['l2_distance'] for v in results['comparison_at_previous'].values() 
                   if v.get('l2_distance') is not None]
        
        results['summary_statistics']['at_previous'] = {
            'mean_cosine_similarity': float(np.mean(cos_sims)) if cos_sims else None,
            'min_cosine_similarity': float(np.min(cos_sims)) if cos_sims else None,
            'max_cosine_similarity': float(np.max(cos_sims)) if cos_sims else None,
            'mean_l2_distance': float(np.mean(l2_dists)) if l2_dists else None,
            'max_l2_distance': float(np.max(l2_dists)) if l2_dists else None,
        }
    
    return results

def print_summary(results: Dict, question_id: int):
    """Print a summary of the comparison results."""
    print(f"\n{'='*80}")
    print(f"Question {question_id} Summary")
    print(f"{'='*80}")
    
    if results.get('status') == 'no_divergence':
        print("No divergence found.")
        return
    
    print(f"Divergence at index: {results['divergence_index']}")
    print(f"Folder 1 generated: '{results['divergent_words']['folder1']}'")
    print(f"Folder 2 generated: '{results['divergent_words']['folder2']}'")
    
    # Summary at divergence
    if 'at_divergence' in results.get('summary_statistics', {}):
        stats = results['summary_statistics']['at_divergence']
        print(f"\nAt divergence point:")
        print(f"  Mean cosine similarity: {stats['mean_cosine_similarity']:.6f}")
        print(f"  Min cosine similarity:  {stats['min_cosine_similarity']:.6f}")
        print(f"  Mean L2 distance:       {stats['mean_l2_distance']:.6f}")
        print(f"  Max L2 distance:        {stats['max_l2_distance']:.6f}")
    
    # Summary at previous
    if 'at_previous' in results.get('summary_statistics', {}):
        stats = results['summary_statistics']['at_previous']
        print(f"\nAt previous point:")
        print(f"  Mean cosine similarity: {stats['mean_cosine_similarity']:.6f}")
        print(f"  Min cosine similarity:  {stats['min_cosine_similarity']:.6f}")
        print(f"  Mean L2 distance:       {stats['mean_l2_distance']:.6f}")
        print(f"  Max L2 distance:        {stats['max_l2_distance']:.6f}")
    
    # Find most divergent submodules at divergence point
    if 'comparison_at_divergence' in results:
        comparisons = results['comparison_at_divergence']
        sorted_by_cos = sorted(
            [(k, v['cosine_similarity']) for k, v in comparisons.items() 
             if v.get('cosine_similarity') is not None],
            key=lambda x: x[1]
        )
        
        print(f"\nTop 5 most divergent submodules (lowest cosine similarity):")
        for i, (key, cos_sim) in enumerate(sorted_by_cos[:5], 1):
            print(f"  {i}. {key:<50} cosine_sim: {cos_sim:.6f}")

def main():
    parser = argparse.ArgumentParser(description="Comprehensive divergence analysis between two exp8 runs.")
    parser.add_argument("folder1", type=str, help="Path to the first results folder.")
    parser.add_argument("folder2", type=str, help="Path to the second results folder.")
    parser.add_argument("--output_file", type=str, default="exp8_part2_comprehensive_divergence_analysis.json", 
                       help="File to save the analysis results.")
    parser.add_argument("--num_questions", type=int, default=1, help="Number of questions to compare.")
    parser.add_argument("--verbose", action="store_true", help="Print detailed summaries for each question.")
    args = parser.parse_args()

    folder1 = Path(args.folder1)
    folder2 = Path(args.folder2)
    
    # Detect number of layers from first question
    print("Detecting number of layers...")
    num_layers = detect_num_layers(folder1 / "question_01")
    print(f"Detected {num_layers} layers in the model.")
    
    all_results = {}

    for i in range(1, args.num_questions + 1):
        question_id = i
        print(f"\n{'='*80}")
        print(f"Comparing question {question_id}...")
        print(f"{'='*80}")

        try:
            with open(folder1 / f"question_{question_id:02d}" / "words.json", 'r') as f:
                words1 = json.load(f)['generated_words']
            with open(folder2 / f"question_{question_id:02d}" / "words.json", 'r') as f:
                words2 = json.load(f)['generated_words']
        except FileNotFoundError:
            print(f"Could not find words.json for question {question_id}. Skipping.")
            continue

        divergence_idx = find_divergence_index(words1, words2)

        if divergence_idx is None:
            print("No divergence found for this question.")
            all_results[f"question_{question_id:02d}"] = {"status": "no_divergence"}
            continue

        print(f"Divergence found at index: {divergence_idx}")
        print(f"  Folder 1: '{words1[divergence_idx]}'")
        print(f"  Folder 2: '{words2[divergence_idx]}'")
        
        # Perform comprehensive analysis
        results = analyze_divergence_comprehensive(
            folder1=folder1,
            folder2=folder2,
            question_id=question_id,
            divergence_idx=divergence_idx,
            num_layers=num_layers
        )
        
        all_results[f"question_{question_id:02d}"] = results
        
        # Print summary if verbose
        if args.verbose:
            print_summary(results, question_id)

    # Save results
    print(f"\n{'='*80}")
    print(f"Saving results to {args.output_file}...")
    with open(args.output_file, 'w') as f:
        json.dump(all_results, f, indent=2)

    print(f"Analysis complete! Results saved to {args.output_file}")
    print(f"{'='*80}")
    
    # Overall summary
    print(f"\n{'OVERALL SUMMARY':^80}")
    print(f"{'='*80}")
    
    diverged_questions = sum(1 for r in all_results.values() if r.get('status') != 'no_divergence')
    print(f"Total questions analyzed: {args.num_questions}")
    print(f"Questions with divergence: {diverged_questions}")
    print(f"Questions without divergence: {args.num_questions - diverged_questions}")
    
    if diverged_questions > 0:
        # Average divergence statistics
        all_cos_sims = []
        all_l2_dists = []
        
        for result in all_results.values():
            if result.get('status') != 'no_divergence':
                if 'at_divergence' in result.get('summary_statistics', {}):
                    stats = result['summary_statistics']['at_divergence']
                    if stats['mean_cosine_similarity'] is not None:
                        all_cos_sims.append(stats['mean_cosine_similarity'])
                    if stats['mean_l2_distance'] is not None:
                        all_l2_dists.append(stats['mean_l2_distance'])
        
        if all_cos_sims:
            print(f"\nAverage cosine similarity at divergence: {np.mean(all_cos_sims):.6f}")
        if all_l2_dists:
            print(f"Average L2 distance at divergence: {np.mean(all_l2_dists):.6f}")

if __name__ == "__main__":
    main()

"""
Example usage:

python exp8_part2_divergence_analysis.py \
    "/home/chashi/Desktop/Research/My Projects/llm_rounding_error_instability/results/A5000_exp8_part5_comprehensive_float32_2025-11-04_10-32-08" \
    "/home/chashi/Desktop/Research/My Projects/llm_rounding_error_instability/results/A6000_exp8_part5_comprehensive_float32_2025-11-04_10-38-04" \
    --num_questions 10 \
    --output_file ../results/exp8_part2_comprehensive_float32_divergence_analysis.json \
    --verbose

Without verbose:
python exp8_part2_comprehensive_divergence_analysis.py \
    "path/to/gpu1/results" \
    "path/to/gpu2/results" \
    --num_questions 10
"""

'''
python src/exp8_part2_divergence_analysis.py results/A5000_exp8_part1_2025-10-30_12-09-20/ results/A6000_exp8_part1_2025-10-30_12-13-27 --num_questions 10
python exp8_part2_divergence_analysis.py "/home/chashi/Desktop/Research/My Projects/llm_rounding_error_instability/results/A5000x2_exp8_part5_comprehensive_2025-11-02_12-49-05" "/home/chashi/Desktop/Research/My Projects/llm_rounding_error_instability/results/A6000_exp8_part5_comprehensive_2025-11-02_12-55-07" --num_questions 3

'''