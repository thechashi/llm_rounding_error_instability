"""
Experiment 15: Stability Boundary L2 Distance Analysis

This experiment builds on Experiment 12 by analyzing the effects of the
smallest possible perturbation that causes a change in the model's output.

Purpose:
--------
To quantify the magnitude of the change in both the input embedding and the
final hidden state representation when crossing the stability boundary.

Methodology:
------------
1.  Load the .npz data file generated by exp12_polar_stability_boundary.py,
    which contains the angles (thetas) and the maximum stable perturbation
    magnitudes (max_s).
2.  Load the Llama model and tokenizer.
3.  Recreate the original input embedding and original final hidden state.
4.  For each angle (theta) and its corresponding max_s:
    a.  Calculate `min_t`, the next representable float value after `max_s` in
        the direction of infinity. This is the smallest perturbation that is
        guaranteed to cause a change in the output.
    b.  Construct the perturbed embedding using `min_t`.
    c.  Calculate the L2 distance between the original embedding and the
        perturbed embedding.
    d.  Pass the perturbed embedding through the model to get the new, changed
        final hidden state.
    e.  Calculate the L2 distance between the original final hidden state and
        the new, changed final hidden state.
5.  Aggregate and analyze these L2 distances (e.g., mean, max, min).
6.  Save the results to a new .npz and .csv file.

Output:
-------
- A new NPZ file containing the original data plus the calculated L2 distances.
- A CSV file for easy analysis.
- A plot visualizing the L2 distances vs. the angle.
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from transformers import AutoTokenizer, AutoModelForCausalLM
import os
import argparse
from tqdm import tqdm

def load_model(model_path="/home/chashi/Desktop/Research/My Projects/models/Llama-3.1-8B-Instruct"):
    """Load model and tokenizer in float32"""
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token

    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        device_map="auto",
        torch_dtype=torch.float32
    )
    return model, tokenizer

def get_hidden_state(model, embeddings, last_token_idx):
    """Get the final hidden state for the last token"""
    with torch.no_grad():
        outputs = model(inputs_embeds=embeddings, output_hidden_states=True)
        hidden_state = outputs.hidden_states[-1][0, last_token_idx, :].cpu().numpy()
    return hidden_state

def analyze_boundary_distances(npz_path, output_dir, precision="float64"):
    """
    Main function to perform L2 distance analysis at the stability boundary.
    """
    print("="*80)
    print("EXPERIMENT 15: Stability Boundary L2 Distance Analysis")
    print("="*80)
    print(f"Loading data from: {npz_path}")
    print(f"Using precision for perturbation: {precision}")

    # Load data from exp12
    data = np.load(npz_path, allow_pickle=True)
    thetas = data['thetas']
    max_s_values = data['max_s_values']
    e1 = data['e1']
    e2 = data['e2']
    input_text = data['input_text'].item()
    num_angles = len(thetas)

    print(f"Found {num_angles} angles to process.")
    print(f"Input text: '{input_text}'")

    # Load model
    print("\n[1/5] Loading model...")
    model, tokenizer = load_model()
    device = next(model.parameters()).device

    # Tokenize input and get original embedding and hidden state
    print("[2/5] Recreating original embedding and hidden state...")
    inputs = tokenizer(input_text, return_tensors="pt").to(device)
    with torch.no_grad():
        original_embeddings = model.model.embed_tokens(inputs["input_ids"])
    
    last_idx = inputs["input_ids"].shape[1] - 1
    original_hidden_state = get_hidden_state(model, original_embeddings, last_idx)
    original_emb_token = original_embeddings[0, last_idx, :].clone()

    e1_tensor = torch.from_numpy(e1).to(device).float()
    e2_tensor = torch.from_numpy(e2).to(device).float()

    embedding_l2_distances = np.zeros(num_angles)
    hidden_state_l2_distances = np.zeros(num_angles)

    print("\n[3/5] Calculating L2 distances at the boundary...")
    for i, theta in enumerate(tqdm(thetas, desc="Processing angles")):
        max_s = np.float32(max_s_values[i])
        min_t = np.nextafter(max_s, np.float32(np.inf))

        direction = torch.cos(torch.tensor(theta, device=device)) * e1_tensor + torch.sin(torch.tensor(theta, device=device)) * e2_tensor

        # Perturb embedding with min_t
        if precision == "float64":
            perturbed_emb_t = (original_emb_token.double() + min_t * direction.double()).float()
        else: # float32
            perturbed_emb_t = original_emb_token + torch.tensor(min_t, device=device) * direction
        
        # Calculate L2 distance for the embedding
        embedding_l2_distances[i] = torch.norm(original_emb_token - perturbed_emb_t).item()

        # Get the new hidden state
        perturbed_embeddings = original_embeddings.clone()
        perturbed_embeddings[0, last_idx, :] = perturbed_emb_t
        changed_hidden_state = get_hidden_state(model, perturbed_embeddings, last_idx)

        # Calculate L2 distance for the hidden state
        hidden_state_l2_distances[i] = np.linalg.norm(original_hidden_state - changed_hidden_state)

    print("\n[4/5] Saving results...")
    os.makedirs(output_dir, exist_ok=True)
    
    output_npz_path = os.path.join(output_dir, "boundary_distance_data.npz")
    np.savez(
        output_npz_path,
        thetas=thetas,
        max_s_values=max_s_values,
        embedding_l2_distances=embedding_l2_distances,
        hidden_state_l2_distances=hidden_state_l2_distances,
        input_text=input_text,
    )
    print(f"Saved data to NPZ: {output_npz_path}")

    csv_path = os.path.join(output_dir, "boundary_distance_data.csv")
    csv_data = np.vstack((thetas, max_s_values, embedding_l2_distances, hidden_state_l2_distances)).T
    np.savetxt(csv_path, csv_data, delimiter=",", header="theta,max_s,embedding_l2_dist,hidden_state_l2_dist", comments="")
    print(f"Saved data to CSV: {csv_path}")

    print("\n" + "="*80)
    print("DISTANCE STATISTICS")
    print("="*80)
    print("--- Embedding L2 Distance ---")
    print(f"Mean:   {np.mean(embedding_l2_distances):.6e}")
    print(f"Median: {np.median(embedding_l2_distances):.6e}")
    print(f"Min:    {np.min(embedding_l2_distances):.6e}")
    print(f"Max:    {np.max(embedding_l2_distances):.6e}")
    print("\n--- Hidden State L2 Distance ---")
    print(f"Mean:   {np.mean(hidden_state_l2_distances):.6e}")
    print(f"Median: {np.median(hidden_state_l2_distances):.6e}")
    print(f"Min:    {np.min(hidden_state_l2_distances):.6e}")
    print(f"Max:    {np.max(hidden_state_l2_distances):.6e}")
    print("="*80)

    print("\n[5/5] Creating plots...")
    # Plotting embedding distances
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.plot(np.degrees(thetas), embedding_l2_distances, color='purple')
    ax.set_title(f'Embedding L2 Distance at Stability Boundary\n"{input_text}"', fontsize=14, fontweight='bold')
    ax.set_xlabel('Angle (degrees)')
    ax.set_ylabel('L2 Distance (Embedding vs Perturbed)')
    ax.grid(True, alpha=0.5)
    plt.tight_layout()
    emb_dist_path = os.path.join(output_dir, "embedding_l2_distance.png")
    plt.savefig(emb_dist_path, dpi=300)
    print(f"Saved embedding distance plot to: {emb_dist_path}")
    plt.close()

    # Plotting hidden state distances
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.plot(np.degrees(thetas), hidden_state_l2_distances, color='green')
    ax.set_title(f'Hidden State L2 Distance at Stability Boundary\n"{input_text}"', fontsize=14, fontweight='bold')
    ax.set_xlabel('Angle (degrees)')
    ax.set_ylabel('L2 Distance (Original vs Changed Hidden State)')
    ax.grid(True, alpha=0.5)
    plt.tight_layout()
    hidden_dist_path = os.path.join(output_dir, "hidden_state_l2_distance.png")
    plt.savefig(hidden_dist_path, dpi=300)
    print(f"Saved hidden state distance plot to: {hidden_dist_path}")
    plt.close()
    
    print("\n" + "="*80)
    print("EXPERIMENT COMPLETE!")
    print("="*80)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Experiment 15: Stability Boundary L2 Distance Analysis")
    parser.add_argument("npz_file", type=str, help="Path to the .npz file from exp12.")
    parser.add_argument("--output_dir", type=str, default=None, help="Directory to save the results. Defaults to a new dir in the same location as the npz file.")
    parser.add_argument("--precision", type=str, choices=["float32", "float64"], default="float64", help="Precision to use for perturbation calculation.")
    
    args = parser.parse_args()

    if args.output_dir is None:
        base_dir = os.path.dirname(args.npz_file)
        npz_filename = os.path.splitext(os.path.basename(args.npz_file))[0]
        output_dir = os.path.join(base_dir, f"exp15_analysis_{npz_filename}_{args.precision}")
    else:
        output_dir = args.output_dir

    analyze_boundary_distances(args.npz_file, output_dir, args.precision)

'''
python3 exp15_stability_boundary_analysis.py "/home/chashi/Desktop/Research/My Projects/llm_rounding_error_instability/results/exp12_2025-12-22_00-51-01_float64_e1_e2/polar_boundary_data.npz" 
================================================================================
DISTANCE STATISTICS FLOAT 64
================================================================================
--- Embedding L2 Distance ---
Mean:   3.861783e-12
Median: 3.139252e-12
Min:    2.058956e-12
Max:    8.595206e-12

--- Hidden State L2 Distance ---
Mean:   8.889576e-05
Median: 8.412415e-05
Min:    8.311980e-05
Max:    9.894477e-05
================================================================================

python3 exp15_stability_boundary_analysis.py "/home/chashi/Desktop/Research/My Projects/llm_rounding_error_instability/results/exp12_2025-12-20_10-55-48_float32_e1_e2/polar_boundary_data.npz" --precision "float32"
================================================================================
DISTANCE STATISTICS FLOAT 32
================================================================================
--- Embedding L2 Distance ---
Mean:   3.861783e-12
Median: 3.139252e-12
Min:    2.058956e-12
Max:    8.595206e-12

--- Hidden State L2 Distance ---
Mean:   8.889576e-05
Median: 8.412415e-05
Min:    8.311980e-05
Max:    9.894477e-05
================================================================================
'''