{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250ac778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSNorm Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6a52a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from utils import load_model\n",
    "def save_rmsnorm_weights_with_stats(model, save_path=\"rmsnorm_weights.npz\"):\n",
    "    \"\"\"\n",
    "    Extracts and saves all RMSNorm weight vectors from a LLaMA model into a .npz file.\n",
    "    Also prints basic statistics (mean, std, min, max, norm) for each RMSNorm layer.\n",
    "    \n",
    "    The saved file contains the ACTUAL weight vectors, not just the stats.\n",
    "    \"\"\"\n",
    "    rms_weights = {}\n",
    "\n",
    "    print(\"\\n=== Extracting RMSNorm weights ===\")\n",
    "    # Iterate through all transformer layers\n",
    "    for i, layer in enumerate(model.model.layers):\n",
    "        for name, module in layer.named_modules():\n",
    "            if \"norm\" in name.lower() and hasattr(module, \"weight\"):\n",
    "                key = f\"layer_{i}_{name}\"\n",
    "                w = module.weight.detach().cpu().float().numpy()\n",
    "                rms_weights[key] = w\n",
    "\n",
    "                # Print stats for this layer\n",
    "                print(f\"{key:45s} | mean={w.mean():.6f} | std={w.std():.6f} | \"\n",
    "                      f\"min={w.min():.6f} | max={w.max():.6f} | norm={np.linalg.norm(w):.6f}\")\n",
    "\n",
    "    # Final RMSNorm before LM head\n",
    "    if hasattr(model.model, \"norm\"):\n",
    "        key = \"final_norm\"\n",
    "        w = model.model.norm.weight.detach().cpu().float().numpy()\n",
    "        rms_weights[key] = w\n",
    "\n",
    "        print(f\"{key:45s} | mean={w.mean():.6f} | std={w.std():.6f} | \"\n",
    "              f\"min={w.min():.6f} | max={w.max():.6f} | norm={np.linalg.norm(w):.6f}\")\n",
    "\n",
    "    # Save all weights\n",
    "    os.makedirs(os.path.dirname(save_path) or \".\", exist_ok=True)\n",
    "    np.savez_compressed(save_path, **rms_weights)\n",
    "\n",
    "    print(f\"\\n✅ Saved {len(rms_weights)} RMSNorm vectors to '{save_path}'\")\n",
    "    return list(rms_weights.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4d6764c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully on device: cuda:0\n",
      "Vocabulary size: 128256\n",
      "\n",
      "=== Extracting RMSNorm weights ===\n",
      "layer_0_input_layernorm                       | mean=0.070758 | std=0.121427 | min=-0.210938 | max=1.085938 | norm=8.994487\n",
      "layer_0_post_attention_layernorm              | mean=0.133770 | std=0.011952 | min=-0.000138 | max=0.234375 | norm=8.595359\n",
      "layer_1_input_layernorm                       | mean=0.105187 | std=0.081226 | min=-0.012451 | max=0.890625 | norm=8.505515\n",
      "layer_1_post_attention_layernorm              | mean=0.166858 | std=0.022191 | min=-0.000052 | max=0.281250 | norm=10.772962\n",
      "layer_2_input_layernorm                       | mean=0.305289 | std=0.098434 | min=-0.001221 | max=0.843750 | norm=20.528986\n",
      "layer_2_post_attention_layernorm              | mean=0.208197 | std=0.029590 | min=-0.000123 | max=0.229492 | norm=13.458517\n",
      "layer_3_input_layernorm                       | mean=0.346206 | std=0.035772 | min=0.002411 | max=0.644531 | norm=22.275162\n",
      "layer_3_post_attention_layernorm              | mean=0.233439 | std=0.027766 | min=-0.000095 | max=0.261719 | norm=15.045430\n",
      "layer_4_input_layernorm                       | mean=0.306154 | std=0.052333 | min=-0.022217 | max=0.703125 | norm=19.878048\n",
      "layer_4_post_attention_layernorm              | mean=0.256258 | std=0.025741 | min=0.000027 | max=0.279297 | norm=16.483027\n",
      "layer_5_input_layernorm                       | mean=0.355024 | std=0.070897 | min=0.081055 | max=0.820312 | norm=23.170187\n",
      "layer_5_post_attention_layernorm              | mean=0.275966 | std=0.028084 | min=-0.000013 | max=0.306641 | norm=17.753023\n",
      "layer_6_input_layernorm                       | mean=0.355845 | std=0.050513 | min=0.087891 | max=0.796875 | norm=23.002361\n",
      "layer_6_post_attention_layernorm              | mean=0.285704 | std=0.026250 | min=-0.000091 | max=0.330078 | norm=18.362082\n",
      "layer_7_input_layernorm                       | mean=0.367191 | std=0.045574 | min=0.091797 | max=0.863281 | norm=23.680521\n",
      "layer_7_post_attention_layernorm              | mean=0.000000 | std=0.000000 | min=0.000000 | max=0.000000 | norm=0.000000\n",
      "layer_8_input_layernorm                       | mean=0.000000 | std=0.000000 | min=0.000000 | max=0.000000 | norm=0.000000\n",
      "layer_8_post_attention_layernorm              | mean=0.000000 | std=0.000000 | min=0.000000 | max=0.000000 | norm=0.000000\n",
      "layer_9_input_layernorm                       | mean=0.399451 | std=0.058577 | min=0.134766 | max=0.949219 | norm=25.838297\n",
      "layer_9_post_attention_layernorm              | mean=0.293691 | std=0.028208 | min=0.066406 | max=0.400391 | norm=18.882717\n",
      "layer_10_input_layernorm                      | mean=0.414824 | std=0.058536 | min=0.112305 | max=1.007812 | norm=26.811769\n",
      "layer_10_post_attention_layernorm             | mean=0.298171 | std=0.031765 | min=0.066895 | max=0.386719 | norm=19.190950\n",
      "layer_11_input_layernorm                      | mean=0.421552 | std=0.062565 | min=0.136719 | max=1.062500 | norm=27.274828\n",
      "layer_11_post_attention_layernorm             | mean=0.302364 | std=0.028406 | min=0.085449 | max=0.384766 | norm=19.436520\n",
      "layer_12_input_layernorm                      | mean=0.392690 | std=0.056215 | min=0.123047 | max=0.917969 | norm=25.388363\n",
      "layer_12_post_attention_layernorm             | mean=0.299507 | std=0.021964 | min=0.068359 | max=0.404297 | norm=19.219944\n",
      "layer_13_input_layernorm                      | mean=0.451036 | std=0.070845 | min=0.120605 | max=1.007812 | norm=29.220243\n",
      "layer_13_post_attention_layernorm             | mean=0.310333 | std=0.020750 | min=0.086426 | max=0.447266 | norm=19.905684\n",
      "layer_14_input_layernorm                      | mean=0.446874 | std=0.059698 | min=0.121582 | max=1.007812 | norm=28.854042\n",
      "layer_14_post_attention_layernorm             | mean=0.327004 | std=0.019007 | min=0.070801 | max=0.445312 | norm=20.963591\n",
      "layer_15_input_layernorm                      | mean=0.445751 | std=0.043757 | min=0.107910 | max=0.957031 | norm=28.665163\n",
      "layer_15_post_attention_layernorm             | mean=0.341950 | std=0.022419 | min=0.076172 | max=0.515625 | norm=21.931770\n",
      "layer_16_input_layernorm                      | mean=0.429070 | std=0.049310 | min=0.086426 | max=0.992188 | norm=27.641190\n",
      "layer_16_post_attention_layernorm             | mean=0.360849 | std=0.029136 | min=0.081055 | max=0.496094 | norm=23.169527\n",
      "layer_17_input_layernorm                      | mean=0.446225 | std=0.040944 | min=0.091797 | max=0.960938 | norm=28.678358\n",
      "layer_17_post_attention_layernorm             | mean=0.373182 | std=0.030807 | min=0.067383 | max=0.486328 | norm=23.964882\n",
      "layer_18_input_layernorm                      | mean=0.459227 | std=0.040352 | min=0.064453 | max=0.996094 | norm=29.503746\n",
      "layer_18_post_attention_layernorm             | mean=0.387954 | std=0.036577 | min=0.066895 | max=0.445312 | norm=24.939188\n",
      "layer_19_input_layernorm                      | mean=0.462713 | std=0.039463 | min=0.090332 | max=0.968750 | norm=29.721132\n",
      "layer_19_post_attention_layernorm             | mean=0.400822 | std=0.038597 | min=0.074219 | max=0.445312 | norm=25.771240\n",
      "layer_20_input_layernorm                      | mean=0.466447 | std=0.051004 | min=0.072754 | max=1.054688 | norm=30.030577\n",
      "layer_20_post_attention_layernorm             | mean=0.413120 | std=0.039414 | min=0.064941 | max=0.460938 | norm=26.559753\n",
      "layer_21_input_layernorm                      | mean=0.459649 | std=0.051801 | min=0.079590 | max=1.039062 | norm=29.603733\n",
      "layer_21_post_attention_layernorm             | mean=0.430598 | std=0.040971 | min=0.071777 | max=0.484375 | norm=27.682709\n",
      "layer_22_input_layernorm                      | mean=0.477886 | std=0.057334 | min=0.075195 | max=1.148438 | norm=30.804043\n",
      "layer_22_post_attention_layernorm             | mean=0.443132 | std=0.045403 | min=0.073242 | max=0.523438 | norm=28.508934\n",
      "layer_23_input_layernorm                      | mean=0.489969 | std=0.050964 | min=0.069824 | max=1.039062 | norm=31.527172\n",
      "layer_23_post_attention_layernorm             | mean=0.456059 | std=0.046781 | min=0.085449 | max=0.535156 | norm=29.340919\n",
      "layer_24_input_layernorm                      | mean=0.492893 | std=0.063772 | min=0.064941 | max=1.140625 | norm=31.808088\n",
      "layer_24_post_attention_layernorm             | mean=0.471161 | std=0.047668 | min=0.058105 | max=0.531250 | norm=30.308249\n",
      "layer_25_input_layernorm                      | mean=0.503976 | std=0.062598 | min=0.066895 | max=1.156250 | norm=32.502289\n",
      "layer_25_post_attention_layernorm             | mean=0.488011 | std=0.047858 | min=0.068359 | max=0.570312 | norm=31.382555\n",
      "layer_26_input_layernorm                      | mean=0.481201 | std=0.070252 | min=0.067871 | max=1.203125 | norm=31.123358\n",
      "layer_26_post_attention_layernorm             | mean=0.506935 | std=0.046297 | min=0.054199 | max=0.554688 | norm=32.578846\n",
      "layer_27_input_layernorm                      | mean=0.516368 | std=0.078609 | min=-0.043457 | max=1.250000 | norm=33.428322\n",
      "layer_27_post_attention_layernorm             | mean=0.528985 | std=0.046050 | min=0.066406 | max=0.574219 | norm=33.983067\n",
      "layer_28_input_layernorm                      | mean=0.508011 | std=0.071923 | min=0.100586 | max=1.289062 | norm=32.836964\n",
      "layer_28_post_attention_layernorm             | mean=0.552964 | std=0.041224 | min=0.076660 | max=0.605469 | norm=35.487926\n",
      "layer_29_input_layernorm                      | mean=0.535148 | std=0.064715 | min=-0.047852 | max=1.195312 | norm=34.499008\n",
      "layer_29_post_attention_layernorm             | mean=0.564638 | std=0.039190 | min=0.090332 | max=0.621094 | norm=36.223801\n",
      "layer_30_input_layernorm                      | mean=0.502133 | std=0.102687 | min=0.098145 | max=1.414062 | norm=32.801643\n",
      "layer_30_post_attention_layernorm             | mean=0.570781 | std=0.044246 | min=0.083984 | max=0.902344 | norm=36.639561\n",
      "layer_31_input_layernorm                      | mean=0.438215 | std=0.088298 | min=0.070801 | max=1.054688 | norm=28.609446\n",
      "layer_31_post_attention_layernorm             | mean=0.479434 | std=0.065481 | min=0.043457 | max=1.375000 | norm=30.968668\n",
      "final_norm                                    | mean=2.344502 | std=0.182112 | min=0.267578 | max=2.937500 | norm=150.500122\n",
      "\n",
      "✅ Saved 65 RMSNorm vectors to '../results/llama_rmsnorm_weights.npz'\n",
      "\n",
      "Example saved keys: ['layer_0_input_layernorm', 'layer_0_post_attention_layernorm', 'layer_1_input_layernorm', 'layer_1_post_attention_layernorm', 'layer_2_input_layernorm']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"/home/chashi/Desktop/Research/My Projects/models/Llama-3.1-8B-Instruct\"\n",
    "model, tokenizer = load_model(MODEL_PATH)\n",
    "\n",
    "keys = save_rmsnorm_weights_with_stats(model, \"../results/llama_rmsnorm_weights.npz\")\n",
    "\n",
    "print(\"\\nExample saved keys:\", keys[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77c3349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
