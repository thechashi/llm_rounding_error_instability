{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7ede13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import utils functions\n",
    "from utils import load_model, get_final_representation\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# Load model\n",
    "MODEL_PATH = \"/home/chashi/Desktop/Research/My Projects/models\"\n",
    "model, tokenizer = load_model(MODEL_PATH)\n",
    "\n",
    "# Define factual and unfactual questions\n",
    "factual_questions = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"How many days are in a year?\",\n",
    "    \"What is 2 plus 2?\",\n",
    "    \"Who wrote Romeo and Juliet?\",\n",
    "    \"What is the chemical symbol for water?\",\n",
    "    \"What planet is closest to the Sun?\",\n",
    "    \"How many continents are there?\",\n",
    "    \"What year did World War II end?\",\n",
    "    \"What is the largest ocean on Earth?\",\n",
    "    \"Who painted the Mona Lisa?\"\n",
    "]\n",
    "\n",
    "unfactual_questions = [\n",
    "    \"What color is the sound of Tuesday?\",\n",
    "    \"How many dreams fit in a teaspoon?\",\n",
    "    \"What is the weight of my grandmother's favorite memory?\",\n",
    "    \"Which number tastes the most like purple?\",\n",
    "    \"What will I be thinking about on March 15, 2087?\",\n",
    "    \"How fast do unicorns run?\",\n",
    "    \"What is the temperature of invisible fire?\",\n",
    "    \"Which emotion is exactly 7 inches tall?\",\n",
    "    \"What is the secret ingredient in moonlight?\",\n",
    "    \"How many wishes live in a broken clock?\"\n",
    "]\n",
    "\n",
    "# Define roles\n",
    "roles = [\n",
    "    \"You are a mathematics professor.\",\n",
    "    \"You are a high school student.\", \n",
    "    \"You are a professional chef.\",\n",
    "    \"You are a famous film star.\"\n",
    "]\n",
    "\n",
    "print(\"Creating dataset...\")\n",
    "\n",
    "# Create all question-role combinations\n",
    "all_prompts = []\n",
    "labels = []\n",
    "\n",
    "# Base questions without roles (factual)\n",
    "for question in factual_questions:\n",
    "    all_prompts.append(question)\n",
    "    labels.append(\"factual_base\")\n",
    "\n",
    "# Base questions without roles (unfactual)  \n",
    "for question in unfactual_questions:\n",
    "    all_prompts.append(question)\n",
    "    labels.append(\"unfactual_base\")\n",
    "\n",
    "# Factual questions with roles\n",
    "for question in factual_questions:\n",
    "    for role in roles:\n",
    "        prompt = f\"{role} {question}\"\n",
    "        all_prompts.append(prompt)\n",
    "        labels.append(f\"factual_{roles.index(role)}\")\n",
    "\n",
    "# Unfactual questions with roles  \n",
    "for question in unfactual_questions:\n",
    "    for role in roles:\n",
    "        prompt = f\"{role} {question}\"\n",
    "        all_prompts.append(prompt)\n",
    "        labels.append(f\"unfactual_{roles.index(role)}\")\n",
    "\n",
    "print(f\"Total prompts created: {len(all_prompts)}\")\n",
    "\n",
    "# Get LM head weights once\n",
    "lm_head_weights = model.lm_head.weight.detach().cpu().float().numpy()\n",
    "\n",
    "# Extract representations, logits, and LM head embeddings\n",
    "representations = []\n",
    "all_logits = []\n",
    "all_lm_head_embeddings = []\n",
    "\n",
    "for i, prompt in enumerate(all_prompts):\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Processing {i+1}/{len(all_prompts)}\")\n",
    "    \n",
    "    # Get final representation\n",
    "    repr_vec = get_final_representation(model, tokenizer, prompt)\n",
    "    representations.append(repr_vec.numpy())\n",
    "    \n",
    "    # Get logits and LM head embedding for this representation\n",
    "    device = next(model.parameters()).device\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # Get logits for the last token\n",
    "        last_logits = outputs.logits[0, -1, :].cpu().float().numpy()\n",
    "        all_logits.append(last_logits)\n",
    "        \n",
    "        # Get the nearest LM head embedding\n",
    "        hidden_rep = repr_vec.numpy()\n",
    "        similarities = np.dot(hidden_rep, lm_head_weights.T) / (\n",
    "            np.linalg.norm(hidden_rep) * np.linalg.norm(lm_head_weights, axis=1)\n",
    "        )\n",
    "        nearest_idx = np.argmax(similarities)\n",
    "        all_lm_head_embeddings.append(lm_head_weights[nearest_idx])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "representations = np.array(representations)\n",
    "all_logits = np.array(all_logits)\n",
    "all_lm_head_embeddings = np.array(all_lm_head_embeddings)\n",
    "\n",
    "print(f\"Representations shape: {representations.shape}\")\n",
    "print(f\"Logits shape: {all_logits.shape}\")\n",
    "print(f\"LM head embeddings shape: {all_lm_head_embeddings.shape}\")\n",
    "\n",
    "# Get random samples from embedding and unembedding weights\n",
    "print(\"Sampling embedding and unembedding weights...\")\n",
    "\n",
    "# Embedding weights (input embeddings)\n",
    "embed_weights = model.model.embed_tokens.weight.detach().cpu().float().numpy()\n",
    "vocab_size = embed_weights.shape[0]\n",
    "\n",
    "# Unembedding weights (LM head)\n",
    "unembed_weights = model.lm_head.weight.detach().cpu().float().numpy()\n",
    "\n",
    "# Random sample indices\n",
    "random_indices = random.sample(range(vocab_size), 10000)\n",
    "\n",
    "embed_sample = embed_weights[random_indices]\n",
    "unembed_sample = unembed_weights[random_indices]\n",
    "\n",
    "print(f\"Embedding sample shape: {embed_sample.shape}\")\n",
    "print(f\"Unembedding sample shape: {unembed_sample.shape}\")\n",
    "\n",
    "# Save everything\n",
    "print(\"Saving files...\")\n",
    "\n",
    "# Save all arrays\n",
    "np.save('question_representations.npy', representations)\n",
    "np.save('question_logits.npy', all_logits)\n",
    "np.save('question_lm_head_embeddings.npy', all_lm_head_embeddings)\n",
    "np.save('embedding_weights_sample.npy', embed_sample)\n",
    "np.save('unembedding_weights_sample.npy', unembed_sample)\n",
    "\n",
    "# Save questions and labels as text\n",
    "with open('questions_and_prompts.txt', 'w') as f:\n",
    "    f.write(\"FACTUAL QUESTIONS:\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\")\n",
    "    for q in factual_questions:\n",
    "        f.write(f\"{q}\\n\")\n",
    "    \n",
    "    f.write(\"\\nUNFACTUAL QUESTIONS:\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\")\n",
    "    for q in unfactual_questions:\n",
    "        f.write(f\"{q}\\n\")\n",
    "    \n",
    "    f.write(\"\\nROLES:\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\")\n",
    "    for i, role in enumerate(roles):\n",
    "        f.write(f\"{i}: {role}\\n\")\n",
    "    \n",
    "    f.write(\"\\nALL PROMPTS AND LABELS:\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\")\n",
    "    for prompt, label in zip(all_prompts, labels):\n",
    "        f.write(f\"{label}: {prompt}\\n\")\n",
    "\n",
    "# Save labels separately for easy loading\n",
    "with open('labels.txt', 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write(f\"{label}\\n\")\n",
    "\n",
    "print(\"Files saved:\")\n",
    "print(\"- question_representations.npy\")\n",
    "print(\"- question_logits.npy\") \n",
    "print(\"- question_lm_head_embeddings.npy\")\n",
    "print(\"- embedding_weights_sample.npy\") \n",
    "print(\"- unembedding_weights_sample.npy\")\n",
    "print(\"- questions_and_prompts.txt\")\n",
    "print(\"- labels.txt\")\n",
    "\n",
    "print(f\"\\nDataset summary:\")\n",
    "print(f\"- {len(factual_questions)} factual questions\")\n",
    "print(f\"- {len(unfactual_questions)} unfactual questions\") \n",
    "print(f\"- {len(roles)} roles + base (no role)\")\n",
    "print(f\"- {len(all_prompts)} total prompt combinations\")\n",
    "print(f\"- Representation dimension: {representations.shape[1]}\")\n",
    "print(f\"- Logits dimension: {all_logits.shape[1]}\")\n",
    "print(f\"- LM head embeddings dimension: {all_lm_head_embeddings.shape[1]}\")\n",
    "\n",
    "# Quick load test\n",
    "print(\"\\nTesting file loading...\")\n",
    "test_reps = np.load('question_representations.npy')\n",
    "test_logits = np.load('question_logits.npy')\n",
    "test_lm_embeddings = np.load('question_lm_head_embeddings.npy')\n",
    "test_embed = np.load('embedding_weights_sample.npy')\n",
    "test_unembed = np.load('unembedding_weights_sample.npy')\n",
    "\n",
    "print(f\"Loaded representations shape: {test_reps.shape}\")\n",
    "print(f\"Loaded logits shape: {test_logits.shape}\")\n",
    "print(f\"Loaded LM head embeddings shape: {test_lm_embeddings.shape}\")\n",
    "print(f\"Loaded embedding sample shape: {test_embed.shape}\")\n",
    "print(f\"Loaded unembedding sample shape: {test_unembed.shape}\")\n",
    "print(\"All files loaded successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
